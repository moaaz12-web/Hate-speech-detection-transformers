{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moaaz12-web/Whisper-BART-GPT-3/blob/master/Whisper%2BGPT_3%2BBART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fh3Q3mWqfT0"
      },
      "source": [
        "# INSTALLING DEPENDENCIES"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make sure to connect to GPU runtime by going to RUNTIME and Change runtime type and selecting GPU from the dropdown.**"
      ],
      "metadata": {
        "id": "718pLV5a5DfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyannote.audio\n",
        "! pip install setuptools==59.5.0"
      ],
      "metadata": {
        "id": "qPSjBYglsH0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yspJcca0mbxw",
        "outputId": "36f7e1d9-f517-4258-d459-30d80350a9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.5.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git  -q\n",
        "!pip install gradio -q \n",
        "! pip install openai transformers\n",
        "! pip install googletrans==3.1.0a0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0trdbEhqm7C"
      },
      "source": [
        "# IMPORTING DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAPkdZyQFDwt"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import whisper\n",
        "import openai\n",
        "from googletrans import Translator\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "import traceback\n",
        "import os\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xluO0pRrqtwO"
      },
      "outputs": [],
      "source": [
        "translator = Translator()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br></br><br></br>"
      ],
      "metadata": {
        "id": "Jakk3And4_vV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh8nQzyXq3uf"
      },
      "source": [
        "# AUDIO TO TEXT AND SUMMARY FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_to_text_model = whisper.load_model(\"medium\")"
      ],
      "metadata": {
        "id": "8XLPzSSvzsqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9IqmwYmE0Zf"
      },
      "outputs": [],
      "source": [
        "def audio_to_trasncript(audio_path, output_language):\n",
        "  try:\n",
        "    result = audio_to_text_model.transcribe(audio_path)\n",
        "  except Exception as e:\n",
        "    print(\"Error transcribing audio file: \", e)\n",
        "    return e\n",
        "\n",
        "  try:\n",
        "    translator = Translator()\n",
        "    translated_transcript = translator.translate(result['text'], dest=output_language).text\n",
        "  except Exception as e:\n",
        "    print(\"Error translating transcript: \", e)\n",
        "    return {\"error\": \"An error occurred while translating the transcrip. Please try again later.\"}, 400\n",
        "\n",
        "  return translated_transcript\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rnpV6Y70Zxf"
      },
      "outputs": [],
      "source": [
        "transcript = audio_to_trasncript('/content/Espanol.mp3', 'English')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "7yWgDBJ_0Hjt",
        "outputId": "d30b6a84-aa07-46ea-c60a-dafea24246a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi, I'm Grecia, from Mexico. I live in the state of Colima, in Villa de Álvarez. In my state you can see two volcanoes. One is fire and the other is snow. My cities are aseismic because the fire volcano is an active volcano and it shakes often. However, I really like being from there because it is a beautiful and peaceful place. The weather is warm most of the year, but there are times when you can see snow on the volcano. Volcanoes also serve to orient people because they indicate where the north is.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br></br><br></br>\n",
        "# TRANSCRIPT SUMMARIZATION"
      ],
      "metadata": {
        "id": "3sC9PAKpz6hL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp-NZ_383xx9"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XB14Cat-CZL"
      },
      "outputs": [],
      "source": [
        "def summarize(ARTICLE, output_language):\n",
        "  translator = Translator()\n",
        "  ARTICLE = translator.translate(ARTICLE, dest='en').text\n",
        "\n",
        "  ARTICLE = ARTICLE.replace('.', '.<eos>')\n",
        "  ARTICLE = ARTICLE.replace('?', '?<eos>')\n",
        "  ARTICLE = ARTICLE.replace('!', '!<eos>')\n",
        "\n",
        "  sentences = ARTICLE.split('<eos>')\n",
        "  current_chunk = 0 \n",
        "  max_chunk = 500\n",
        "  chunks = []\n",
        "  for sentence in sentences:\n",
        "      if len(chunks) == current_chunk + 1: \n",
        "          if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
        "              chunks[current_chunk].extend(sentence.split(' '))\n",
        "          else:\n",
        "              current_chunk += 1\n",
        "              chunks.append(sentence.split(' '))\n",
        "      else:\n",
        "          print(current_chunk)\n",
        "          chunks.append(sentence.split(' '))\n",
        "\n",
        "  for chunk_id in range(len(chunks)):\n",
        "      chunks[chunk_id] = ' '.join(chunks[chunk_id])\n",
        "\n",
        "  res = summarizer(chunks, max_length=120, min_length=30, do_sample=False)\n",
        "  text = ' '.join([summ['summary_text'] for summ in res])\n",
        "\n",
        "  translated_summary = translator.translate(text, dest=output_language).text\n",
        "  return translated_summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarize(\"\"\"\n",
        "\n",
        "Hi, I'm Grecia, from Mexico. I live in the state of Colima, in Villa de Álvarez. \n",
        "In my state you can see two volcanoes. One is fire and the other is snow. \n",
        "My cities are aseismic because the fire volcano is an active volcano and it shakes often. \n",
        "However, I really like being from there because it is a beautiful and peaceful place. \n",
        "The weather is warm most of the year, but there are times when you can see snow on the volcano. \n",
        "Volcanoes also serve to orient people because they indicate where the north is.\n",
        "\n",
        "\"\"\",  \"Spanish\")\n",
        "\n",
        "\n",
        "summarize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8XrIJwY0sI8",
        "outputId": "915f11b7-3d3e-4471-e498-fd9374b3836a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cunsA4zMAITJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "outputId": "50d11f50-c7de-4587-e16a-719fc6fefbd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:217: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "languages = [\"English\", \"Spanish\", \"French\", \"German\", \"Italian\", \"Creole\", \"Portuguese\", \"Russian\", \"Chinese\", \"Japanese\", \"Korean\"]\n",
        "article_input = gr.inputs.Textbox(label=\"Transcript\")\n",
        "language_input = gr.inputs.Dropdown(choices=languages, label=\"Output Language\")\n",
        "output = gr.outputs.Textbox(label=\"Summary\")\n",
        "\n",
        "gr.Interface(fn=summarize, inputs=[article_input, language_input], outputs=output, \n",
        "             title=\"Transcript Summarizer\", description=\"Summarize any transcript in the language of your choice.\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br></br><br></br>\n",
        "# QUESTION ANSWERING USING GPT-3"
      ],
      "metadata": {
        "id": "KNsp8sTA2NGu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzgUw5PRAH5m"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import re\n",
        "\n",
        "# Set up the OpenAI API credentials\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Define the GPT-3 model to use (e.g. \"davinci\" for GPT-3's largest model)\n",
        "model_engine = \"text-davinci-002\"\n",
        "\n",
        "# Define the maximum length of the context window\n",
        "max_window_length = 1800\n",
        "\n",
        "\n",
        "def answer_question(question, context, output_language):\n",
        "    translator = Translator()\n",
        "    question  = translator.translate(question, dest='en').text\n",
        "    context = translator.translate(context, dest='en').text\n",
        "\n",
        "    # Split the context into smaller windows of length less than or equal to max_window_length\n",
        "    context_windows = re.findall(r\".{1,%d}\" % max_window_length, context, re.DOTALL)\n",
        "\n",
        "    # Process each context window separately and generate an answer for each window\n",
        "    answers = []\n",
        "    for window in context_windows:\n",
        "        prompt = f\"question: {question}\\ncontext: {window}\\nanswer:\"\n",
        "        response = openai.Completion.create(\n",
        "            engine=model_engine,\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_window_length,\n",
        "            n=1,\n",
        "            stop=None,\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        answer = response.choices[0].text.strip()\n",
        "        answers.append(answer)\n",
        "\n",
        "    # Concatenate the answers from each window into a single answer string\n",
        "    answer = \" \".join(answers)\n",
        "\n",
        "    answer = translator.translate(answer, dest=output_language).text\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = answer_question(\"Why does she like licving there?\", \n",
        "\n",
        "\"\"\"\n",
        "Hi, I'm Grecia, from Mexico. I live in the state of Colima, in Villa de Álvarez. In my state you can see two volcanoes. \n",
        "One is fire and the other is snow. My cities are aseismic because the fire volcano is an active volcano and it shakes often. \n",
        "However, I really like being from there because it is a beautiful and peaceful place. \n",
        "The weather is warm most of the year, but there are times when you can see snow on the volcano. \n",
        "Volcanoes also serve to orient people because they indicate where the north is.\n",
        "\n",
        "\"\"\",  \"Urdu\"\n",
        ")"
      ],
      "metadata": {
        "id": "Tpx-qc0K2Y_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WoCcry5z26wd",
        "outputId": "3c62fa1c-29bb-45f3-bf06-ca4db3c3b51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'گریشیا کولیما میں رہنا پسند کرتی ہے کیونکہ یہ ایک خوبصورت اور پرامن جگہ ہے جہاں سال کے بیشتر موسم گرم ہوتے ہیں۔'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "languages = [\"English\", \"Spanish\", \"French\", \"German\", \"Italian\", \"Creole\", \"Portuguese\", \"Russian\", \"Chinese\", \"Japanese\", \"Korean\"]\n",
        "\n",
        "\n",
        "gr.Interface(fn=answer_question, \n",
        "             inputs=[gr.inputs.Textbox(label=\"Question\"), \n",
        "                     gr.inputs.Textbox(label=\"Context\") ,\n",
        "                     gr.inputs.Dropdown(languages, label=\"Output Language\")], \n",
        "             outputs=gr.outputs.Textbox(label=\"Answer\"), title=\"Question answering with GPT-3\", description=\"Give context and ask questions in any language\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "SuLn2Dv-4j0f",
        "outputId": "7dd746d5-6481-4f84-bd43-9f4f87ca0cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:217: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7863, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRDsNAqj3Khz"
      },
      "source": [
        "<br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br><br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpfryx6U3ROK"
      },
      "source": [
        "# IGNORE ALL OF THIS BELOW THIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIyMlkAylIoB",
        "outputId": "ca1ffbaf-9216-4801-ba67-d82730816a38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:10<00:00, 140MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "audio_to_text_model = whisper.load_model(\"medium\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EsrNjvLsMtpC",
        "outputId": "59c796b2-fcf8-4ad2-e7a6-1495842e50c3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" Hello, my name is Ksenia. I have been married for 4 years and I have a small son, he is 2.5 years old. When Misha and I decided to get married, the question immediately arose about where we would live. There were two options. To rent someone else's apartment or to take a loan for a new one. We decided to take a mortgage loan for 10 years. The mortgage payments are about a third of our family income. Therefore, at the moment we are forced to refuse ourselves on trips or other large purchases. Although, in my opinion, the interest rates in Russian mortgage loans are very high, nevertheless, our young family can live independently, separately from their parents, in their own apartment.\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = audio_to_text_model.transcribe('/content/Russian.mp3', task='translate')\n",
        "result['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9dWWMXeMk9f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "summarizer_tokenizer = AutoTokenizer.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
        "summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(\"philschmid/bart-large-cnn-samsum\")\n",
        "\n",
        "token = summarizer_tokenizer(result['text'], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "summary = summarizer_model.generate(**token)\n",
        "res = summarizer_tokenizer.decode(summary[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lrMTuHwjowZ"
      },
      "outputs": [],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "QA_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased-distilled-squad')\n",
        "QA_model = DistilBertModel.from_pretrained('distilbert-base-cased-distilled-squad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Nt30YeDOkYI"
      },
      "outputs": [],
      "source": [
        "context = result['text']\n",
        "questions = []\n",
        "number = int(input(\"Enter how many questions you want to ask? \"))\n",
        "\n",
        "for i in range(len(number)):\n",
        "  ques = input(\"Type in your question number \", i,  \": \\n\", )\n",
        "  questions.append(ques)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6xkF7zTOk28"
      },
      "outputs": [],
      "source": [
        "def QA(transcript, question, output_language):\n",
        "  translator = Translator()\n",
        "  translated_transcript = translator.translate(transcript, dest='en').text\n",
        "  translated_question = translator.translate(question, dest='en').text\n",
        "\n",
        "  prompt = \"Passange:\\n\" + translated_transcript + \"\\n Question: \" + translated_question\n",
        "  openai.api_key = \"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\"\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt =  prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=3500 ,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        "  )\n",
        "  \n",
        "\n",
        "  answer =  response['choices'][0]['text']\n",
        "  translated_answer = translator.translate(answer, dest=output_language).text\n",
        "\n",
        "  return translated_answer\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Je12CoZqj-93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXkwf1ckMnLy"
      },
      "outputs": [],
      "source": [
        "for i in range(questions):\n",
        "  inputs = QA_tokenizer(questions[i], context, return_tensors=\"pt\")\n",
        "  with torch.no_grad():\n",
        "      outputs = QA_model(**inputs)\n",
        "  print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeq-6DnMMpAN"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "def GPT3_Completion(prompt):\n",
        "  openai.api_key = \"\"\n",
        "  response = openai.Completion.create(\n",
        "  engine=\"text-davinci-002\",\n",
        "  prompt =  prompt,\n",
        "  temperature=0.7,\n",
        "  max_tokens=3500 ,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        "  )\n",
        "  \n",
        "\n",
        "  return response['choices'][0]['text']\n",
        "\n",
        "t1 = \"From the context provided below, answer the questions: \\n\"\n",
        "prompt = t1 + context\n",
        "for i in questions:\n",
        "  prompt += i + \"\\n\"\n",
        "  \n",
        "answers = GPT_Completion(prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdTyyRhLMSaF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "wUNJvLrFmSsN",
        "outputId": "95289092-1304-4bfc-bf33-265d7358617e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def voice_to_text(audio_input):\n",
        "    # Your code to convert the audio input to text\n",
        "    text_output = \"Example text output based on the audio input\"\n",
        "    return text_output\n",
        "\n",
        "inputs = gr.inputs.Audio()\n",
        "outputs = gr.outputs.Textbox()\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=voice_to_text, \n",
        "    inputs=inputs, \n",
        "    outputs=outputs,\n",
        "    title=\"Voice to Text\", \n",
        "    description=\"Convert audio input to text output\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "RUiZT9nAHjkv",
        "outputId": "cfa70d9b-07f1-4195-b92b-c13925d331e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Interface, please remove them: {'button_text': 'Summarize', 'style': {'description_width': 'initial'}}\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def summarize_text(text):\n",
        "    # code to summarize the text\n",
        "    summarized_text = \"This is the summarized text.\"\n",
        "    return summarized_text\n",
        "\n",
        "inputs = [gr.inputs.Textbox(type='text',  label=\"Enter Text\")]\n",
        "outputs = [gr.outputs.Textbox(type='text', label=\"Summarized Text\")]\n",
        "\n",
        "interface = gr.Interface(\n",
        "    summarize_text, inputs=inputs, outputs=outputs,\n",
        "    button_text=\"Summarize\",\n",
        "    style={\"description_width\":\"initial\"}\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EdNkydVJyq-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnPpWMOaYd6R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa0H6MFuYd2i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6N5Dyz-YdzW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUVERFbTYdwC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}